\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[russian]{babel}
\usepackage{xcolor}

\begin{document}
\subsection*{Наивный байес и центроидный классификатор}

По определению байесовского классификатора,
необходимо найти $$class(x) =
argmax_y {P(y)\prod_{k=1}^n}P(x^{(k)}|y)$$
Априорная вероятность одинакова для всех классов и равна $P_c$.
Плотность распределения признаков равна
$$P(x^{(k)}|y) = \frac{1}{\sqrt{2 \pi \sigma^2}}
e^{-\frac{x^{(k) - \mu_{yk}}^2}{2\sigma^2}}
\qquad \forall k \in \{ 1, n\}$$
Тогда:
$$ class(x) = argmax_y {P_c
\prod_{k=1}^n}\frac{1}{\sqrt{2 \pi \sigma^2}}
e^{-\frac {({x^{(k)} - \mu_{yk})}^2}{2\sigma^2}} $$
Прологарифмируем рассматриваемое произведение:
$$ L(x, y) = ln(P_c) + ln(\frac{n}{\sqrt{2 \pi \sigma^2}})
+ \sum_{k=1}^n {-\frac {({x^{(k)} - \mu_{yk})}^2}{2\sigma^2}} $$
Нахождение $argmax_y(L(x, y))$ эквивалентно нахождению
$argmax_y$ исходной функции.
Рассмотрим только ту часть функции, которая зависит от y
(остальная часть не влияет на $argmax_y(L(x, y))$)
Остается только
$$ \sum_{k=1}^n {-{(x^{(k)} - \mu_{yk}})}^2 = -\rho^2(x, \mu_y) $$
То есть нахождение $argmax_yL(x,y)$ эквивалентно минимизации расстояния от x до $\mu_y$ по всевозможным $y$. Продолжая цепочку эквивалентностей обратно, получаем требуемое утверждение.


\end{document}
